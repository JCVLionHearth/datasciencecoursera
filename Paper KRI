\documentclass[a4paper,12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{geometry}
\geometry{left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}

\title{Sistema de Indicadores Claves de Riesgo (KRI) Observado y Prospectivo Basado en Redes Neuronales}
\author{Nombre del Autor}
\date{\today}

\begin{document}

\maketitle

\section{Introducción}

El presente documento describe el desarrollo de un sistema de Indicadores Clave de Riesgo (KRI) enfocado en la predicción de quejas en diferentes temáticas y regionales utilizando Redes Neuronales. Este sistema consta de dos tipos de KRI:
\begin{itemize}
    \item \textbf{KRI Prospectivo}: basado en predicciones a futuro mediante el uso de redes neuronales (ARNN).
    \item \textbf{KRI Observado}: calculado a partir de los datos actuales, permitiendo medir el desempeño y comparar con las predicciones.
\end{itemize}
El propósito del KRI es alertar sobre posibles desviaciones que puedan requerir acciones preventivas en la gestión de riesgos.

\section{Predicción de Frecuencia de Quejas (KRI Prospectivo)}

Para realizar predicciones de la frecuencia de quejas, se utilizó una Arquitectura de Redes Neuronales Recurrentes (ARNN). Este tipo de red es adecuado para manejar secuencias de datos, capturando patrones temporales como tendencias y estacionalidades. Las series temporales de datos históricos son alimentadas a la red, permitiendo predecir la frecuencia de quejas en los próximos 12 meses.

\subsection{Arquitectura de la Red}
La arquitectura utilizada incluye las siguientes características:
\begin{itemize}
    \item \textbf{Longitud de la secuencia}: Se utilizaron secuencias de 24 meses para realizar la predicción del mes siguiente.
    \item \textbf{Capas}: Una capa densa con 50 neuronas para capturar la dependencia temporal, seguida de una capa de \textit{dropout} con una tasa del 20\% para evitar el sobreajuste.
    \item \textbf{Función de activación}: ReLU para las capas internas.
    \item \textbf{Número de épocas}: El modelo fue entrenado por 50 épocas para optimizar el ajuste a los datos.
\end{itemize}

\section{Cálculo del Promedio y Desviación Estándar (KRI Observado)}

Para establecer una línea de base para el KRI Observado, se seleccionan los últimos 24 meses de datos históricos. Este período es suficiente para capturar la estacionalidad anual y otras fluctuaciones regulares en las series de quejas.

\subsection{Justificación del Periodo de 24 Meses}
El uso de 24 meses garantiza que se tomen en cuenta variaciones estacionales y tendencias anuales, permitiendo obtener una medida representativa de la frecuencia típica de las quejas.

\subsection{Eliminación de Valores Atípicos}
Se empleó el método del rango intercuartílico (IQR) para identificar y eliminar valores atípicos. Estos valores extremos pueden distorsionar el cálculo del promedio y la desviación estándar, por lo que su exclusión asegura una representación más precisa de los datos.

\section{Definición de Umbrales y Alertas}

\subsection{Cálculo de los Umbrales}
Para definir los umbrales de alerta se utiliza un intervalo de confianza basado en la fórmula:

\[
\text{Umbral Max} = \bar{X} + 0.524 \cdot \sigma
\]
\[
\text{Umbral Min} = \bar{X} - 0.524 \cdot \sigma
\]

donde $\bar{X}$ y $\sigma$ son el promedio y la desviación estándar de los últimos 24 meses sin valores atípicos. El valor de 0.524 corresponde a un nivel de confianza del 40\%.

\subsection{Alertas Basadas en Predicciones}
Las alertas se definen en función de las proyecciones futuras y los umbrales calculados:

\begin{itemize}
    \item \textbf{Alerta Baja}: Si la proyección mensual es menor que el Umbral Min.
    \item \textbf{Alerta Media}: Si la proyección mensual está entre el Umbral Min y el Umbral Max.
    \item \textbf{Alerta Extrema}: Si la proyección mensual supera el Umbral Max.
\end{itemize}

\section{Recomendaciones}

\subsection{Revisión Periódica}
Se recomienda una revisión periódica de los KRIs para asegurar que las predicciones se ajusten adecuadamente a los datos observados.

\subsection{Ajuste del Intervalo de Confianza}
El intervalo de confianza puede ajustarse según la sensibilidad y especificidad deseadas en las alertas. Un ajuste de los umbrales influirá en la cantidad de alertas generadas.

\subsection{Validación de Resultados}
Es esencial validar los resultados predichos con los datos observados para garantizar que las redes neuronales capturan de manera precisa las tendencias y patrones.

\section{Conclusión}

El uso de redes neuronales recurrentes en la predicción de quejas permite establecer un KRI Prospectivo que puede alertar sobre posibles incrementos en la frecuencia de quejas, proporcionando a las organizaciones la capacidad de tomar decisiones proactivas. Simultáneamente, el KRI Observado ofrece una visión clara del desempeño actual, basada en datos históricos filtrados y ajustados, estableciendo umbrales clave para la detección de anomalías. Ambos KRIs son esenciales para una gestión de riesgos eficiente, permitiendo a las organizaciones mitigar riesgos de manera proactiva y reactiva.

\end{document}

Hola he realizado con ayuda de redes neuronales predicciones de eventos en el tiempo, con esta información se busca realizar un KRI prospectivo con el fin de identificar momentos en el tiempo en los que pueden haber alertas asociadas a quejas de diferentes temáticas y en diferentes regionales, hice unos paso muy breves descritos a continuación, pero quiero hacer un documento que permita a cualquiera que lo lea entenderlo, ya que ellos reportaran las cifras y les pedirán explicaciones. Ayudame creando un documento que describa cada paso a detalle, la necesidad de este paso y además pueda entenderse...quiero un documento que describa la importancia del KRI y además que explique que variables como la de los umbrales serán utilizadas para los KRI observados, es decir para los datos que actualmente suceden. Es decir hay dos KRIs el KRI prospectivo y el KRI observado.  

1. Predicciones de la Frecuencia de quejas: Se utilizó redes neuronales (ARNN) para hacer predicciones basadas en datos históricos, son adecuadas para manejar secuencias de datos y pueden capturar tendencias y estacionalidades en series temporales.

2. Cálculo del Promedio de los Últimos 24 Meses: Se seleccionan los últimos 24 meses de datos para calcular el promedio y la desviación estándar. El período de 24 meses permite tener en cuenta la estacionalidad anual y otros patrones que pueden repetirse.

3. Eliminación de Valores Atípicos: Se utiliza el método del rango intercuartil (IQR) para identificar y excluir valores atípicos. Esto se hace para asegurar que el promedio y la desviación estándar no sean distorsionados por valores extremos. Al excluirlos, se obtiene una medida más representativa del comportamiento típico de los datos.

4. Definición del Umbral con el Intervalo de Confianza (Min-Max): Se utiliza intervalos de confianzas para definir los umbrales de alerta.

𝑈𝑚𝑏𝑟𝑎𝑙_𝑚𝑎𝑥=𝑋 ̅+0,524∙𝜎
𝑈𝑚𝑏𝑟𝑎𝑙_𝑚𝑖𝑛=𝑋 ̅−0,524∙𝜎

Donde 𝑋 ̅ y 𝜎 son los respectivos promedios y desviación estándar de los últimos 24 meses sin considerar datos atípicos, para cada una de las series temáticas de quejas, el valor de 0,524 hace referencia al z-score de un nivel de confianza del 40%.

5. Alertas

𝐴𝑙𝑒𝑟𝑡𝑎_𝑏𝑎𝑗𝑎⇒𝑃𝑟𝑜𝑦𝑒𝑐𝑐𝑖𝑜𝑛_𝑚𝑒𝑛𝑠𝑢𝑎𝑙<𝑈𝑚𝑏𝑟𝑎𝑙_𝑚𝑖𝑛
𝐴𝑙𝑒𝑟𝑡𝑎_𝑚𝑒𝑑𝑖𝑎⇒𝑈𝑚𝑏𝑟𝑎𝑙_𝑚𝑖𝑛<𝑃𝑟𝑜𝑦𝑒𝑐𝑐𝑖𝑜𝑛_𝑚𝑒𝑛𝑠𝑢𝑎𝑙≤𝑈𝑚𝑏𝑟𝑎𝑙_𝑚𝑎𝑥
𝐴𝑙𝑒𝑟𝑡𝑎_𝑒𝑥𝑡𝑟𝑒𝑚𝑎⇒𝑃𝑟𝑜𝑦𝑒𝑐𝑐𝑖𝑜𝑛_𝑚𝑒𝑛𝑠𝑢𝑎𝑙>𝑈𝑚𝑏𝑟𝑎𝑙_𝑚𝑎𝑥

Recomendaciones
Revisión Periódica
Ajuste del Intervalo de Confianza
Validación de Resultados
Disclaimers

Se asume que los datos se distribuyen normalmente.
Sensibilidad y Especificidad: Ajustar el umbral puede cambiar la sensibilidad y especificidad de las alertas.
Dependencia de Datos Históricos: La precisión de las predicciones y la detección de alertas dependen de la calidad y representatividad de los datos históricos.

Agrego una porción del codigo, reducelo a la arquitectura más relevante:
SEQ_LENGTH = 24  # Usar 24 meses para predecir el siguiente mes
EPOCHS = 50
NEURONAS=50
# Crear un archivo Excel para guardar las predicciones
writer = pd.ExcelWriter('predicciones_series_ejemplo.xlsx', engine='xlsxwriter')
# Bucle para cada serie
for serie in ['Serie1', 'Serie2', 'Serie3', 'Serie4', 'Serie5','Serie6','Serie7','Serie8', 'Serie9', 'Serie10', 'Serie11', 'Serie12','Serie13','Serie14','Serie15','Serie16','Serie17']:
   print(f"Procesando {serie}...")
   # Crear secuencias de entrenamiento y etiquetas
   X, y = create_sequences(df[serie].values, SEQ_LENGTH)
   # Dividir los datos en conjuntos de entrenamiento y prueba
   split = int(0.7 * len(X))
   X_train, X_test = X[:split], X[split:]
   y_train, y_test = y[:split], y[split:]
   # Redimensionar los datos para que sean compatibles con LSTM [samples, time steps, features]
   X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
   X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))
   # Construir el modelo LSTM con Dropout
   model = Sequential()
   model.add(Dense(NEURONAS, activation='relu', input_shape=(SEQ_LENGTH,))) #capa con # neuronas para capturar la dependencia temporal
   model.add(Dropout(0.2)) #20% Esto ayuda a evitar el sobreajuste
   model.add(Dense(1)) #capa densa con una neurona para producir la predicción para el siguiente paso temporal
   model.compile(optimizer='adam', loss='mse')
   # Entrenar el modelo
   history = model.fit(X_train, y_train, epochs=EPOCHS, validation_data=(X_test, y_test), verbose=1)
   # Predecir en el conjunto de prueba
   y_pred = model.predict(X_test)
   # Calcular los errores y la desviación estándar
   errors = y_test - y_pred.flatten()
   std_error = np.std(errors)
   # Calcular el intervalo de confianza (IC 95%)
   confidence_interval_90 = 1.96 * std_error
   # Visualizar resultados del conjunto de prueba con intervalo de confianza
#    plt.figure(figsize=(10, 6))
#    plt.plot(range(len(y_test)), y_test, label='Actual')
#    plt.plot(range(len(y_pred)), y_pred, label='Predicted')
#    plt.fill_between(range(len(y_pred)),
#                     y_pred.flatten() - confidence_interval_90,
#                     y_pred.flatten() + confidence_interval_90,
#                     color='b', alpha=0.2, label='95% Confidence Interval')
#    plt.title(f"Predicción de la frecuencia de {serie} con IC 95% (ARNN)")
#    plt.xlabel("Tiempo")
#    plt.ylabel("Frecuencia")
#    plt.legend()
#    plt.savefig(f'prediccion_{serie}.png')
#    plt.show()
   # Predecir los próximos 12 meses con intervalos de confianza
   n_months = 12
   last_sequence = df[serie].values[-SEQ_LENGTH:]  # Tomar la última secuencia de longitud SEQ_LENGTH
   future_predictions = []
   future_confidences = []
   for _ in range(n_months):
       input_seq = last_sequence.reshape((1, SEQ_LENGTH, 1))
       next_pred = model.predict(input_seq)
       future_predictions.append(next_pred[0, 0])
       future_confidences.append(confidence_interval_90)
       last_sequence = np.append(last_sequence[1:], next_pred)  # Actualizar la secuencia para la siguiente predicción
   # Crear una lista de fechas para los próximos 12 meses
   last_date = df['Fecha'].iloc[-1]
   future_dates = [last_date + pd.DateOffset(months=i) for i in range(1, n_months + 1)]
   # Crear un DataFrame con las predicciones futuras
   future_df = pd.DataFrame({
       'Fecha': future_dates,
       f'Frecuencia_Predicha_{serie}': future_predictions,
       f'Limite_Superior_{serie}': np.array(future_predictions) + np.array(future_confidences),
       f'Limite_Inferior_{serie}': np.array(future_predictions) - np.array(future_confidences)
   })
   # Calcular el promedio histórico y la desviación estándar de los últimos 24 meses
   historical_window = 24
   ventana_total=df[serie].tail(historical_window)
   # Calcular los cuartiles y el rango intercuartil
   Q1 = ventana_total.quantile(0.25)
   Q3 = ventana_total.quantile(0.75)
   IQR = Q3 - Q1
   # Definir los límites para los valores atípicos
   lower_bound = Q1 - 1* IQR
   upper_bound = Q3 + 1* IQR
   # Filtrar los valores que no son atípicos
   filtered_data = ventana_total[(ventana_total >= lower_bound) & (ventana_total <= upper_bound)]
   # Calcular el promedio y la desviación estándar de los datos filtrados
   historical_mean = filtered_data.mean() #historical_mean = df[serie].tail(historical_window).mean()
   historical_std = filtered_data.std()   #historical_std = df[serie].tail(historical_window).std()
   # Añadir el promedio de los ultimos 24 meses al DataFrame
   future_df[f'promedioUlt24meses_{serie}'] = historical_mean
   #Umbral
   threshold0 = historical_mean - 0.524*historical_std #-40% de confianza
   threshold1 = historical_mean + 0.524*historical_std #+40% de confianza
   threshold2 = historical_mean + 1.645*historical_std #90% de confianza
   # Añadir el umbral al DataFrame
   future_df[f'UmbralMin_{serie}'] = threshold0
   future_df[f'UmbralMax_{serie}'] = threshold1

genera el documento en formato latex
