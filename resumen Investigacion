
La gestión ética en proyectos de Inteligencia Artificial enfrenta varios desafíos, incluyendo la falta de comprensión generalizada sobre la inteligencia artificial (IA), el acceso desigual a tecnología y recursos de IA, y el uso de datos sensibles sin normativas claras. Además, se subestiman las consecuencias éticas, hay una falta de diversidad en los equipos de desarrollo, y existen deficiencias en la regulación y supervisión. Estos problemas pueden llevar a sesgos y discriminación, pérdida de confianza en la IA, exclusión de grupos vulnerables, y conflictos legales, entre otras consecuencias.El estado del arte actual en la ética de la IA refleja una preocupación global y transversal por los impactos de la tecnología en múltiples aspectos de la vida humana. Los autores de estos trabajos coinciden en la necesidad urgente de regular y diseñar tecnologías de IA que sean transparentes, responsables y justas. El creciente enfoque en la explicabilidad, la alfabetización en IA y las directrices éticas muestra que el futuro de la IA no solo depende de avances técnicos, sino también de un enfoque profundo en la responsabilidad ética.

La propuesta describe el desarrollo de una plataforma de evaluación ética automatizada que utiliza un agente de inteligencia artificial (IA) para evaluar y emitir juicios sobre las dimensiones éticas de proyectos tecnológicos. La plataforma se basa en modelos de machine learning y procesamiento de lenguaje natural (NLP), integrando técnicas de aprendizaje supervisado, no supervisado y un sistema de recomendación basado en reglas. El agente de IA evaluará los proyectos según criterios éticos clave, incluyendo equidad, transparencia, privacidad, impacto social y seguridad, aprovechando datos históricos y directrices éticas reconocidas. Además, la plataforma proporcionará recomendaciones prácticas para mitigar riesgos éticos, promoviendo un desarrollo tecnológico responsable. El reentrenamiento continuo del agente de IA asegurará la conformidad con los estándares y prácticas éticas en evolución.

La plataforma permitiría auditorías éticas continuas y automatizadas, facilitando la identificación de riesgos éticos y generando recomendaciones personalizadas. Esto fomentará una cultura de responsabilidad ética en la innovación tecnológica. Al proporcionar un marco robusto y sistemático para la toma de decisiones éticas, la plataforma contribuirá a la creación de tecnologías de IA que sean transparentes, responsables y justas. Además, ayudará a mitigar las consecuencias éticas, legales, sociales y económicas asociadas con el uso de IA, promoviendo un desarrollo tecnológico más equitativo y seguro.

Cancela-Outeda, C. (2023). The EU’s AI act: A framework for collaborative governance. Journal Name, 27, 101291.
Chauncey, S. A., & McKenna, H. P. (2023). A framework and exemplars for ethical and responsible use of AI chatbot technology to support teaching and learning. Journal Name, 5, 100182.
Inglada Galiana, L., Corral Gudino, L., & Miramontes González, P. (2023). Ethics and artificial intelligence. Journal Name, 224(3), 178–186.
Kong, S.-C., Cheung, M.-Y. W., & Tsang, O. (2023). Developing an artificial intelligence literacy framework: Evaluation of a literacy course for senior secondary students using a project-based learning approach. Journal Name, 6, 100214.
Kulkarni, A. V., Joseph, S., & Patil, K. P. (2023). Artificial intelligence technology readiness for social sustainability and business ethics: Evidence from MSMEs in developing nations. Journal Name, 4(2), 100250.
