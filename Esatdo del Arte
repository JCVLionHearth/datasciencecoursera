Hola, con la información bibliografíca que te suministro más adelantes debes hacer lo siguiente:
1. Categorizar los articulos de 5 a 6 grupos o categorías tales como: Ética en la Construcción y la Ingeniería, Derechos Humanos y Sostenibilidad, Desarrollo de Directrices Éticas, Explicabilidad y Transparencia, Responsabilidad y Gobernanza Colaborativa, Derechos de autor
2. Construir una matriz del estado de arte coon los siguientes campos
Artículo
Autores
Tipo
Resumen
Metodología
Categoría (grupos creados en el punto 1)
Revista/Tipo q1,q2
Año
País
Variable 1
Variable 2
Variable n

Ejemplo de variables	
	
Variable 1	Metodología de desarrollo
Variable 2	Población de experimentación
Variable 3	Tipo de sistema
Variable 4	Algoritmo
Variable 5	Categoría de investigación
Variable 6	Categoría temática
Variable 7	Disciplina

3. para cada categoría definir un resumen de dos parrafos que involucren los articulos mas relevantes para cada grupo, inluyendo las siguientes temáticas:

Descripción del texto (si es un libro resultado de investigación, capítulo de libro, revista, tesis o monografía)	
Problema de investigación (incluye la pregunta, si la hay)
Tipo de investigación o enfoque metodológico y/o propuesta de intervención (si la hay)	
Conclusiones principales

esta es la bibliografia te la envío en dos partes:

parte 1:
@article{caicedo-consuegra_algoritmos_nodate,
	title = {Algoritmos de inteligencia artificial basada en perfiles socio conductuales para la segmentación inteligente de clientes: estudio de caso.},
	volume = {25},
	issn = {0123-3033},
	url = {https://openurl-ebsco-com.hemeroteca.lasalle.edu.co/contentitem/doi:10.25100/iyc.v25i3.12658?sid=ebsco:plink:crawler&id=ebsco:doi:10.25100/iyc.v25i3.12658&crl=c},
	doi = {10.25100/iyc.v25i3.12658},
	shorttitle = {Algoritmos de inteligencia artificial basada en perfiles socio conductuales para la segmentación inteligente de clientes},
	pages = {1--17},
	number = {3},
	journaltitle = {Ingeniería y Competitividad},
	author = {Caicedo-Consuegra, Lady D. and Márquez-Vásquez, Paula A. and Meza-Pérez, Alberto M.},
	urldate = {2024-08-24},
	langid = {english},
	note = {Publisher: Universidad del Valle},
	file = {Snapshot:C\:\\Users\\57314\\Zotero\\storage\\7XAEWLZ7\\xbntmhp52v.html:text/html;Texto completo:C\:\\Users\\57314\\Zotero\\storage\\K2U86KP7\\Caicedo-Consuegra et al. - Algoritmos de inteligencia artificial basada en perfiles socio conductuales para la segmentación int.pdf:application/pdf},
}


@article{noauthor_impacto_2023,
	title = {Impacto de la inteligencia artificial en los métodos de evaluación en la educación primaria y secundaria: revisión sistemática de la literatura},
	volume = {28},
	issn = {1136-1034},
	url = {https://www-sciencedirect-com.hemeroteca.lasalle.edu.co/science/article/pii/S1136103423000114},
	doi = {10.1016/j.psicod.2023.06.001},
	shorttitle = {Impacto de la inteligencia artificial en los métodos de evaluación en la educación primaria y secundaria},
	abstract = {El sector educativo puede enriquecerse con la incorporación de la inteligencia artificial ({IA}) en diversos aspectos. El campo de la inteligencia artif…},
	pages = {93--103},
	number = {2},
	journaltitle = {Revista de Psicodidáctica},
	urldate = {2024-09-30},
	date = {2023-07-01},
	langid = {american},
	note = {Publisher: Elsevier},
	file = {Snapshot:C\:\\Users\\57314\\Zotero\\storage\\H6ERW4JX\\S1136103423000114.html:text/html},
}

@article{ning_generative_2024,
	title = {Generative artificial intelligence and ethical considerations in health care: a scoping review and ethics checklist},
	volume = {0},
	issn = {2589-7500},
	url = {https://www.thelancet.com/journals/landig/article/PIIS2589-7500(24)00143-2/fulltext},
	doi = {10.1016/S2589-7500(24)00143-2},
	shorttitle = {Generative artificial intelligence and ethical considerations in health care},
	number = {0},
	journaltitle = {The Lancet Digital Health},
	shortjournal = {The Lancet Digital Health},
	author = {Ning, Yilin and Teixayavong, Salinelat and Shang, Yuqing and Savulescu, Julian and Nagaraj, Vaishaanth and Miao, Di and Mertens, Mayli and Ting, Daniel Shu Wei and Ong, Jasmine Chiat Ling and Liu, Mingxuan and Cao, Jiuwen and Dunn, Michael and Vaughan, Roger and Ong, Marcus Eng Hock and Sung, Joseph Jao-Yiu and Topol, Eric J. and Liu, Nan},
	urldate = {2024-10-15},
	date = {2024-09-17},
	pmid = {39294061},
	note = {Publisher: Elsevier},
}

@article{inglada_galiana_ethics_2024,
	title = {Ethics and artificial intelligence},
	volume = {224},
	issn = {2254-8874},
	url = {https://www.sciencedirect.com/science/article/pii/S2254887424000213},
	doi = {10.1016/j.rceng.2024.02.003},
	abstract = {The relationship between ethics and artificial intelligence in medicine is a crucial and complex topic that falls within its broader context. Ethics in medical artificial intelligence ({AI}) involves ensuring that technologies are safe, fair, and respect patient privacy. This includes concerns about the accuracy of diagnoses provided by artificial intelligence, fairness in patient treatment, and protection of personal health data. Advances in artificial intelligence can significantly improve healthcare, from more accurate diagnoses to personalized treatments. However, it is essential that developments in medical artificial intelligence are carried out with strong ethical consideration, involving healthcare professionals, artificial intelligence experts, patients, and ethics specialists to guide and oversee their implementation. Finally, transparency in artificial intelligence algorithms and ongoing training for medical professionals are fundamental.
Resumen
La relación entre ética e inteligencia artificial en medicina es un tema crucial y complejo y se encuadra en su contexto más amplio. Así, la ética en inteligencia artificial ({IA}) médica implica asegurar que las tecnologías sean seguras, justas y respeten la privacidad de los pacientes. Esto incluye preocuparse sobre la precisión de los diagnósticos proporcionados por la {IA}, la equidad en el tratamiento de pacientes y la protección de los datos personales de salud. Los avances en inteligencia artificial pueden mejorar significativamente la atención médica, desde diagnósticos más precisos hasta tratamientos personalizados. Sin embargo, es esencial que los desarrollos en inteligencia artificial médica se realicen con una consideración ética fuerte, involucrando a los pacientes, profesionales de la salud e inteligencia artificial y especialistas en ética para guiar y supervisar su implementación. Por último, es fundamental la transparencia en los algoritmos de inteligencia artificial y la formación continua para los profesionales médicos.},
	pages = {178--186},
	number = {3},
	journaltitle = {Revista Clínica Española (English Edition)},
	shortjournal = {Revista Clínica Española (English Edition)},
	author = {Inglada Galiana, L. and Corral Gudino, L. and Miramontes González, P.},
	urldate = {2024-10-15},
	date = {2024-03-01},
	keywords = {Artificial intelligence, Ethics, Ética, Explainability, Explicabilidad, Inteligencia artificial},
	file = {ScienceDirect Snapshot:C\:\\Users\\57314\\Zotero\\storage\\EUAVV7M2\\S2254887424000213.html:text/html},
}

@online{noauthor_ethics_nodate,
	title = {Ethics of artificial intelligence and robotics in the architecture, engineering, and construction industry - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/abs/pii/S0926580524001055?via%3Dihub},
	urldate = {2024-10-15},
	file = {Ethics of artificial intelligence and robotics in the architecture, engineering, and construction industry - ScienceDirect:C\:\\Users\\57314\\Zotero\\storage\\Z4EJEFLK\\S0926580524001055.html:text/html},
}

@article{lesandrini_ethics_2023,
	title = {The Ethics of Artificial Intelligence and Machine Learning},
	volume = {42},
	issn = {1546-0843},
	url = {https://www.sciencedirect.com/science/article/pii/S1546084323000603},
	doi = {10.1016/j.jradnu.2023.05.001},
	pages = {265--266},
	number = {3},
	journaltitle = {Journal of Radiology Nursing},
	shortjournal = {Journal of Radiology Nursing},
	author = {Lesandrini, Jason and Idris, Muhammed Y. and Reis, David S.},
	urldate = {2024-10-15},
	date = {2023-09-01},
	file = {ScienceDirect Snapshot:C\:\\Users\\57314\\Zotero\\storage\\QBIGR3CN\\S1546084323000603.html:text/html},
}

@article{stahl_exploring_2023,
	title = {Exploring ethics and human rights in artificial intelligence – A Delphi study},
	volume = {191},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162523001877},
	doi = {10.1016/j.techfore.2023.122502},
	abstract = {Ethical and human rights issues of artificial intelligence ({AI}) are a prominent topic of research and innovation policy as well as societal and scientific debate. It is broadly recognised that {AI}-related technologies have properties that can give rise to ethical and human rights concerns, such as privacy, bias and discrimination, safety and security, economic distribution, political participation or the changing nature of warfare. Numerous ways of addressing these issues have been suggested. In light of the complexity of this discussion, we undertook a Delphi study with experts in the field to determine the most pressing issues and prioritise appropriate mitigation strategies. The results of the study demonstrate the difficulty of defining clear priorities. Our findings suggest that the debate around ethics and human rights of {AI} would benefit from being reframed and more strongly emphasising the systems nature of {AI} ecosystems.},
	pages = {122502},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Stahl, Bernd Carsten and Brooks, Laurence and Hatzakis, Tally and Santiago, Nicole and Wright, David},
	urldate = {2024-10-15},
	date = {2023-06-01},
	keywords = {Ethics, Artificial intelligence ({AI}), Delphi, Expert stakeholders, Human rights, Policy issues},
	file = {ScienceDirect Snapshot:C\:\\Users\\57314\\Zotero\\storage\\NUBDMGTQ\\S0040162523001877.html:text/html;Texto completo:C\:\\Users\\57314\\Zotero\\storage\\RUBT85TZ\\Stahl et al. - 2023 - Exploring ethics and human rights in artificial intelligence – A Delphi study.pdf:application/pdf},
}

@article{kulkarni_artificial_2024,
	title = {Artificial intelligence technology readiness for social sustainability and business ethics: Evidence from {MSMEs} in developing nations},
	volume = {4},
	issn = {2667-0968},
	url = {https://www.sciencedirect.com/science/article/pii/S2667096824000399},
	doi = {10.1016/j.jjimei.2024.100250},
	shorttitle = {Artificial intelligence technology readiness for social sustainability and business ethics},
	abstract = {Social, economic, and environmental development together contributes to sustainable development. Social sustainability ({SS}) is essential to create just and inclusive societies where people's basic needs are satisfied, human rights are protected, and social cohesion and fairness exist. To achieve holistic, sustainable development, policymakers and management must consider {SS} and environmental and economic considerations. Employees' social and behavioral interactions impact {SS} and business ethics. Micro, small, and medium enterprises ({MSMEs}) can learn from artificial intelligence ({AI}) for better decision-making, operational optimization, increased employability, and employee empowerment. Therefore, this research aims to assess how artificial intelligence technology affects {SS} and business ethics in the {MSMEs}. We studied the artificial intelligence ({AI}) readiness among {MSME} companies in developing nations. We analyzed {AI} readiness using the theory of technology-organization-environment ({TOE}). Further, we also studied {AI} readiness and its influence on business ethics and {SS}, which we measured through skill development, work conditions, environment, and safety among {MSMEs}. We collected the data from 236 {MSME} employees. We used Structural Equation Modeling using {SmartPLS} software for data analysis. The research findings indicated that {AI} readiness directly impacts {SS}. We also found that the findings directly impact employees' social and ethical behavior. We also observed that business ethics significantly affects {SS}, indicating partial mediation. This study has substantial theoretical and managerial implications as policymakers and {MSME} leadership need to consider {SS} an essential component of sustainable development.},
	pages = {100250},
	number = {2},
	journaltitle = {International Journal of Information Management Data Insights},
	shortjournal = {International Journal of Information Management Data Insights},
	author = {Kulkarni, Apoorva Vikrant and Joseph, Shaji and Patil, Kanchan Pranay},
	urldate = {2024-10-15},
	date = {2024-11-01},
	keywords = {Artificial intelligence, Business ethics, Micro small medium enterprise, Social sustainability, Sustainable development goal, Technology-organization-environment},
}

@article{malmio_ethics_2023,
	title = {Ethics as an enabler and a constraint – Narratives on technology development and artificial intelligence in military affairs through the case of Project Maven},
	volume = {72},
	issn = {0160-791X},
	url = {https://www.sciencedirect.com/science/article/pii/S0160791X22003347},
	doi = {10.1016/j.techsoc.2022.102193},
	abstract = {Project Maven is an {AI}-induced information technology for military applications initiated by the United States Department of Defence ({DoD}) in 2017 and originally signed on to a civilian contractor, namely Google. However, this initiative raised massive resistance from a substantial amount of Google employees, eventually leading to the contract's annulation. This article uses narrative analysis to investigate enabling and constraining arguments of {AI} for military purposes that appeared in the debate following the public announcement of Project Maven. In addition, the article highlights the co-production of ethics, technology, and the complex issues that arise from civilian-military exchanges in technology development. Enabling arguments associated with consequentialist ethics are identified as narratives of accuracy and maintenance. Accuracy constitutes a guiding principle for saving civilian lives, while maintenance is directed at keeping the power balance intact. In contrast, constraining arguments proceed from deontological ethics that emphasize disengagement and ambivalence. Disengagement amplifies a civilian/military divide, while ambivalence exhibits conflicting views concerning the prospect of supplementing technological solutions that have the potential to contribute to war and civilian casualties. Conclusively, security narratives and technological storytelling are important aspects to consider since they hold a performative function that influences the framing and mobilization of security and technology development.},
	pages = {102193},
	journaltitle = {Technology in Society},
	shortjournal = {Technology in Society},
	author = {Malmio, Irja},
	urldate = {2024-10-15},
	date = {2023-02-01},
	keywords = {Ethics, Conflicting values, Military {AI}, Security narratives, Socio-technical imaginaries},
	file = {ScienceDirect Snapshot:C\:\\Users\\57314\\Zotero\\storage\\CDBPZTEQ\\S0160791X22003347.html:text/html},
}

@article{mullins_creating_2021,
	title = {Creating ethics guidelines for artificial intelligence and big data analytics customers: The case of the consumer European insurance market},
	volume = {2},
	issn = {2666-3899},
	url = {https://www.sciencedirect.com/science/article/pii/S2666389921002245},
	doi = {10.1016/j.patter.2021.100362},
	shorttitle = {Creating ethics guidelines for artificial intelligence and big data analytics customers},
	abstract = {The European Union ({EU}) has a strong reputation and track record for the development of guidelines for the ethical use of artificial intelligence ({AI}) generally. In this paper, we discuss the development of an {AI} and ethical framework by the European Insurance and Occupational Pensions Authority ({EIOPA}), for the European insurance market. {EIOPA}'s earlier report on big data analytics ({EIOPA}, 2019) provided a foundation to analyze the complex range of issues associated with {AI} being deployed in insurance, such as behavioral insurance, parametric products, novel pricing and risk assessment algorithms, e-service, and claims management. The paper presents an overview of {AI} in insurance applications throughout the insurance value chain. A general discussion of ethics, {AI}, and insurance is provided, and a new hierarchical model is presented that describes insurance as a complex system that can be analyzed by taking a layered, multi-level approach that maps ethical issues directly to specific level(s).},
	pages = {100362},
	number = {10},
	journaltitle = {Patterns},
	shortjournal = {Patterns},
	author = {Mullins, Martin and Holland, Christopher P. and Cunneen, Martin},
	urldate = {2024-10-15},
	date = {2021-10-08},
	keywords = {{AI}, {AI} ethics, {AI} governance, {AI} regulation, data analytics, insurance, {InsurTech}, risk},
	file = {Texto completo:C\:\\Users\\57314\\Zotero\\storage\\Q8WIA8PK\\Mullins et al. - 2021 - Creating ethics guidelines for artificial intelligence and big data analytics customers The case of.pdf:application/pdf},
}

@article{sreenivasan_design_2024,
	title = {Design thinking and artificial intelligence: A systematic literature review exploring synergies},
	volume = {8},
	issn = {2096-2487},
	url = {https://www.sciencedirect.com/science/article/pii/S2096248724000201},
	doi = {10.1016/j.ijis.2024.05.001},
	shorttitle = {Design thinking and artificial intelligence},
	abstract = {This article examines how design thinking and artificial intelligence ({AI}) work together and what it means for the design sector. The goal is to understand how {AI} technologies may advance the design process, encourage innovation, and produce more individualized and user-centric solutions. This study intends to shed light on the potential of {AI} as a catalyst for creativity and the ethical implications of {AI}-driven design by discovering overlapping ideas and methodologies between design thinking and {AI}. According to the research, {AI} can significantly influence the design process by eliminating tedious processes, improving user-centricity, and stimulating creativity. {AI} may support designers’ decision-making, prototyping, and ideation processes, resulting in more creative and effective design solutions. Addressing bias in {AI} algorithms and data privacy is imperative to ensure ethical {AI} integration. Virtual reality, bio-design, and inclusive design are untapped areas where {AI} can be used.},
	pages = {297--312},
	number = {3},
	journaltitle = {International Journal of Innovation Studies},
	shortjournal = {International Journal of Innovation Studies},
	author = {Sreenivasan, Aswathy and Suresh, M.},
	urldate = {2024-10-15},
	date = {2024-09-01},
	keywords = {Artificial intelligence, Ethics, Data privacy, Design thinking, Systematic review},
}


@article{das_informatics_2023,
	title = {Informatics on a social view and need of ethical interventions for wellbeing via interference of artificial intelligence},
	volume = {11},
	issn = {2772-5030},
	url = {https://www.sciencedirect.com/science/article/pii/S2772503023000257},
	doi = {10.1016/j.teler.2023.100065},
	abstract = {The main focus of this paper was to discuss and appraise the attribution of intelligence and value judgement on Artificial Intelligence ({AI}) and its regulated use in society. Humans are tool-making creatures and {AI} is used for civilization via tools. During the time of pre-civilization, tools were simple in the form of crude construction, using hand skills but at present, the achievements are the substitution of machinery to relieve/replace human intellect. {AI} is the scientific technique of bringing learning, adaptation, and self-organization of machines. It encompasses various concepts and methods, deployed by researchers in many diverse fields of computation and cognition. This is the computational mode of a brain, based on artificial neural networks. The usefulness of {AI} ethically, initiates a big question i.e. if the human mind is not self-sufficient for any work without harming the moral sentiment of others then, how can people believe in a computational model of the mind, is a machine, morally responsible for any good or bad action. We highlight issues on the use of {AI} in the replacement of the human mind asking what is the value of humans in this age of {AI}? Can {AI} reciprocate and respect human values better than human beings? Can {AI} replace human intelligence? In the case of ethical enquiry, it is rather a herculean task to consider a machine's action to be moral or immoral, after all, it is just a machinery action devoid of any moral quality.},
	pages = {100065},
	journaltitle = {Telematics and Informatics Reports},
	shortjournal = {Telematics and Informatics Reports},
	author = {Das, Kabita and Pattanaik, Manaswini and Basantia, Smitimayee and Mishra, Radhashyam and Das, Debashreemayee and Sahoo, Kanhucharan and Paital, Biswaranjan},
	urldate = {2024-10-15},
	date = {2023-09-01},
	keywords = {Artificial intelligence, Ethical enquiry, Ethics in technology, Human conduct, Human intelligence, Moral value, Social cognition},
}

@article{ray_benchmarking_2023,
	title = {Benchmarking, ethical alignment, and evaluation framework for conversational {AI}: Advancing responsible development of {ChatGPT}},
	volume = {3},
	issn = {2772-4859},
	url = {https://www.sciencedirect.com/science/article/pii/S2772485923000534},
	doi = {10.1016/j.tbench.2023.100136},
	shorttitle = {Benchmarking, ethical alignment, and evaluation framework for conversational {AI}},
	abstract = {Conversational {AI} systems like {ChatGPT} have seen remarkable advancements in recent years, revolutionizing human–computer interactions. However, evaluating the performance and ethical implications of these systems remains a challenge. This paper delves into the creation of rigorous benchmarks, adaptable standards, and an intelligent evaluation methodology tailored specifically for {ChatGPT}. We meticulously analyze several prominent benchmarks, including {GLUE}, {SuperGLUE}, {SQuAD}, {CoQA}, Persona-Chat, {DSTC}, {BIG}-Bench, {HELM} and {MMLU} illuminating their strengths and limitations. This paper also scrutinizes the existing standards set by {OpenAI}, {IEEE}’s Ethically Aligned Design, the Montreal Declaration, and Partnership on {AI}’s Tenets, investigating their relevance to {ChatGPT}. Further, we propose adaptive standards that encapsulate ethical considerations, context adaptability, and community involvement. In terms of evaluation, we explore traditional methods like {BLEU}, {ROUGE}, {METEOR}, precision–recall, F1 score, perplexity, and user feedback, while also proposing a novel evaluation approach that harnesses the power of reinforcement learning. Our proposed evaluation framework is multidimensional, incorporating task-specific, real-world application, and multi-turn dialogue benchmarks. We perform feasibility analysis, {SWOT} analysis and adaptability analysis of the proposed framework. The framework highlights the significance of user feedback, integrating it as a core component of evaluation alongside subjective assessments and interactive evaluation sessions. By amalgamating these elements, this paper contributes to the development of a comprehensive evaluation framework that fosters responsible and impactful advancement in the field of conversational {AI}.},
	pages = {100136},
	number = {3},
	journaltitle = {{BenchCouncil} Transactions on Benchmarks, Standards and Evaluations},
	shortjournal = {{BenchCouncil} Transactions on Benchmarks, Standards and Evaluations},
	author = {Ray, Partha Pratim},
	urldate = {2024-10-15},
	date = {2023-09-01},
	keywords = {Adaptive standards, Benchmarks, {ChatGPT}, Conversational {AI}, Evaluation framework, Intelligent evaluation},
}

@article{noauthor_development_2022,
	title = {The development process of Responsible {AI}: The case of {ASSISTANT}*},
	volume = {55},
	issn = {2405-8963},
	url = {https://www-sciencedirect-com.hemeroteca.lasalle.edu.co/science/article/pii/S2405896322016251},
	doi = {10.1016/j.ifacol.2022.09.360},
	shorttitle = {The development process of Responsible {AI}},
	abstract = {The development of artificial intelligence ({AI}) for manufacturing comes with the question of why and how to make sure that the resulting system acts r…},
	pages = {7--12},
	number = {10},
	journaltitle = {{IFAC}-{PapersOnLine}},
	urldate = {2024-10-15},
	date = {2022-01-01},
	langid = {american},
	note = {Publisher: Elsevier},
	file = {Snapshot:C\:\\Users\\57314\\Zotero\\storage\\5VEPGT29\\S2405896322016251.html:text/html},
}

@article{fu_navigating_2024,
	title = {Navigating the ethical terrain of {AI} in education: A systematic review on framing responsible human-centered {AI} practices},
	volume = {7},
	issn = {2666-920X},
	url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001097},
	doi = {10.1016/j.caeai.2024.100306},
	shorttitle = {Navigating the ethical terrain of {AI} in education},
	abstract = {With the rapid development of artificial intelligence ({AI}) in recent years, there has been an increasing number of studies on integrating {AI} in various educational contexts, ranging from early childhood to higher education. Although systematic reviews have widely reported the effects of {AI} on teaching and learning, limited reviews have examined and defined responsible {AI} in education ({AIED}). To fill this gap, we conducted a convergent systematic mixed studies review to analyze key themes emerging from primary research. Following the Preferred Reporting Items for Systematic Review and Meta-Analysis ({PRISMA}) guidelines, we searched Scopus and Web of Science and identified 40 empirical studies that satisfied our inclusion criteria. Specifically, we used four criteria for the screening process: (1) the study's full text was available in English; (2) the study was published before April 10th, 2024 in peer-reviewed journals or conference proceedings; (3) the study was primary research that collected original data and applied qualitative, quantitative, or mixed-methods as the study methodology; and (4) the study had a clear focus on ethical and/or responsible {AI} in one or multiple educational context(s). Our findings identified essential stakeholders and characteristics of responsible {AI} in K-20 educational contexts and expanded understanding of responsible human-centered {AI} ({HCAI}). We unveiled characteristics vital to {HCAI}, encompassing Fairness and Equity, Privacy and Security, Non-maleficence and Beneficence, Agency and Autonomy, and Transparency and Intelligibility. In addition, we provided suggestions on how to achieve responsible {HCAI} via collaborative efforts of stakeholders, including roles of users (e.g., students and educators), developers, researchers, and policy and decision-makers.},
	pages = {100306},
	journaltitle = {Computers and Education: Artificial Intelligence},
	shortjournal = {Computers and Education: Artificial Intelligence},
	author = {Fu, Yao and Weng, Zhenjie},
	urldate = {2024-10-15},
	date = {2024-12-01},
	keywords = {Educational contexts, Responsible human-centered artificial intelligence, Systematic mixed studies review},
	file = {ScienceDirect Snapshot:C\:\\Users\\57314\\Zotero\\storage\\S25I4J9G\\S2666920X24001097.html:text/html},
}

#####
PARTE 2

@article{shukla_ai_2024,
	title = {{AI} as a user of {AI}: Towards responsible autonomy},
	volume = {10},
	issn = {2405-8440},
	url = {https://www.sciencedirect.com/science/article/pii/S2405844024074280},
	doi = {10.1016/j.heliyon.2024.e31397},
	shorttitle = {{AI} as a user of {AI}},
	abstract = {Recent advancements in Artificial Intelligence ({AI}), particularly in generative language models and algorithms, have led to significant impacts across diverse domains. {AI} capabilities to address prompts are growing beyond human capability but we expect {AI} to perform well also as a prompt engineer. Additionally, {AI} can serve as a guardian for ethical, security, and other predefined issues related to generated content. We postulate that enforcing dialogues among {AI}-as-prompt-engineer, {AI}-as-prompt-responder, and {AI}-as-Compliance-Guardian can lead to high-quality and responsible solutions. This paper introduces a novel {AI} collaboration paradigm emphasizing responsible autonomy, with implications for addressing real-world challenges. The paradigm of responsible {AI}-{AI} conversation establishes structured interaction patterns, guaranteeing decision-making autonomy. Key implications include enhanced understanding of {AI} dialogue flow, compliance with rules and regulations, and decision-making scenarios exemplifying responsible autonomy. Real-world applications envision {AI} systems autonomously addressing complex challenges. We have made preliminary testing of such a paradigm involving instances of {ChatGPT} autonomously playing various roles in a set of experimental {AI}-{AI} conversations and observed evident added value of such a framework.},
	pages = {e31397},
	number = {11},
	journaltitle = {Heliyon},
	shortjournal = {Heliyon},
	author = {Shukla, Amit K. and Terziyan, Vagan and Tiihonen, Timo},
	urldate = {2024-10-15},
	date = {2024-06-15},
	keywords = {{ChatGPT}, {AI} accountability, Artificial Intelligence ({AI}), Autonomy, Prompt engineering, Responsible {AI}},
	file = {ScienceDirect Snapshot:C\:\\Users\\57314\\Zotero\\storage\\HMQ5A53J\\S2405844024074280.html:text/html;Texto completo:C\:\\Users\\57314\\Zotero\\storage\\KHDWZ4MK\\Shukla et al. - 2024 - AI as a user of AI Towards responsible autonomy.pdf:application/pdf},
}

@article{harfouche_ai_2024,
	title = {{AI} ethics on the road to responsible {AI} plant science and societal welfare},
	volume = {29},
	issn = {1360-1385},
	url = {https://www.sciencedirect.com/science/article/pii/S1360138523004156},
	doi = {10.1016/j.tplants.2023.12.016},
	series = {Special issue: 21st century tools in plant science},
	abstract = {The swiftness of artificial intelligence ({AI}) progress in plant science begets relevant ethical questions with significant scientific and societal implications. Embracing a principled approach to regulation, ethics review and monitoring, and human-centric interpretable informed {AI} ({HIAI}), we can begin to navigate our voyage towards ethical and socially responsible {AI}.},
	pages = {104--107},
	number = {2},
	journaltitle = {Trends in Plant Science},
	shortjournal = {Trends in Plant Science},
	author = {Harfouche, Antoine L. and Petousi, Vasiliki and Jung, Wonsup},
	urldate = {2024-10-15},
	date = {2024-02-01},
	keywords = {{AI} ethics, ethics review and monitoring, interpretability, regulation, responsibility, trustworthy {AI}},
}

@article{akbarighatar_sociotechnical_2023,
	title = {A sociotechnical perspective for responsible {AI} maturity models: Findings from a mixed-method literature review},
	volume = {3},
	issn = {2667-0968},
	url = {https://www.sciencedirect.com/science/article/pii/S266709682300040X},
	doi = {10.1016/j.jjimei.2023.100193},
	shorttitle = {A sociotechnical perspective for responsible {AI} maturity models},
	abstract = {As artificial intelligence ({AI}) is increasingly used in various industries, it becomes crucial for organizations to enhance their capabilities and maturity in adopting {AI} responsibly. This paper employs a mixed-method approach that combines topic modeling with manual content analysis to provide a comprehensive review of the literature on {AI} maturity and readiness. The review encompasses an extensive corpus of 1451 papers, identifying the main themes and topics within this body of literature. Based on these findings, a subset of papers was selected and further analyzed to identify {AI} capabilities utilizing a sociotechnical lens. This further analysis led to the identification of foundational and responsible {AI} ({RAI}) capabilities. These capabilities have been integrated in a sociotechnical framework of capabilities for {AI} maturity models providing valuable insights for organizations and {AI} service providers and a basis for further research.},
	pages = {100193},
	number = {2},
	journaltitle = {International Journal of Information Management Data Insights},
	shortjournal = {International Journal of Information Management Data Insights},
	author = {Akbarighatar, Pouria and Pappas, Ilias and Vassilakopoulou, Polyxeni},
	urldate = {2024-10-15},
	date = {2023-11-01},
	keywords = {Artificial intelligence, Maturity model, Responsible {AI} capabilities, Sociotechnical, Topic modeling},
	file = {Texto completo:C\:\\Users\\57314\\Zotero\\storage\\J8MNAE9C\\Akbarighatar et al. - 2023 - A sociotechnical perspective for responsible AI maturity models Findings from a mixed-method litera.pdf:application/pdf},
}

@article{chauncey_framework_2023,
	title = {A framework and exemplars for ethical and responsible use of {AI} Chatbot technology to support teaching and learning},
	volume = {5},
	issn = {2666-920X},
	url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000619},
	doi = {10.1016/j.caeai.2023.100182},
	abstract = {The aim of this paper is to investigate the ethical and responsible use of {AI} chatbots in education in support of critical thinking, cognitive flexibility and self-regulation in terms of their potential to enhance and motivate teaching and learning in contemporary education environments. {AI} chatbots such as {ChatGPT} by {OpenAI} appear to be improving in conversational and other capabilities and this paper explores such advances using version 4. Based on a review of the research literature, a conceptual framework is formulated for responsible use of {AI} chatbots in education supporting cognitive flexibility in {AI}-rich learning environments. The framework is then operationalized for use in this paper through the development of exemplars for math, english language arts ({ELA}), and studying with {ChatGPT} to close learning gaps in an effort to foster more ethical and responsible approaches to the design and development of {AI} chatbots for application and use in teaching and learning environments. This paper extends earlier foundational work on cognitive flexibility and {AI} chatbots as well as work on cognitive flexibility in support of creativity and innovation with {AI} chatbots in urban civic spaces.},
	pages = {100182},
	journaltitle = {Computers and Education: Artificial Intelligence},
	shortjournal = {Computers and Education: Artificial Intelligence},
	author = {Chauncey, Sarah A. and {McKenna}, H. Patricia},
	urldate = {2024-10-15},
	date = {2023-01-01},
	keywords = {{AI} ethics, {AI} responsibility, {AI}-Rich learning environments, Cognitive flexibility, Critical thinking, Self-regulation},
}

@article{noauthor_explainable_2024,
	title = {Explainable {AI} for all - A roadmap for inclusive {XAI} for people with cognitive disabilities},
	volume = {79},
	issn = {0160-791X},
	url = {https://www-sciencedirect-com.hemeroteca.lasalle.edu.co/science/article/pii/S0160791X24002331},
	doi = {10.1016/j.techsoc.2024.102685},
	abstract = {Artificial intelligence ({AI}) is increasingly prevalent in our daily lives, setting specific requirements for responsible development and deployment: T…},
	pages = {102685},
	journaltitle = {Technology in Society},
	urldate = {2024-10-15},
	date = {2024-12-01},
	langid = {american},
	note = {Publisher: Pergamon},
}

@article{hendawy_starting_2024,
	title = {A starting framework for urban {AI} applications},
	issn = {2090-4479},
	url = {https://www.sciencedirect.com/science/article/pii/S2090447924003629},
	doi = {10.1016/j.asej.2024.102987},
	abstract = {There has been a growing concern about the ethical implications of Artificial Intelligence ({AI}) in urban environments. Scholars have highlighted the dual nature of {AI}, which can both enhance urban sustainability and pose significant privacy risks. The literature acknowledges that {AI} introduces specific challenges in urban contexts. However, there remains a gap in comprehensive sector-specific ethical frameworks tailored to the unique challenges posed by {AI} applications in cities. This study aims to fill this gap by proposing a starting framework for the ethics of Urban {AI} applications, providing principles to guide responsible {AI} development and deployment in urban settings. The study employed a two-phase methodology: a content analysis of 100 {AI} ethics documents to develop a preliminary framework, followed by a survey of experts and stakeholders to validate and expand this framework by identifying urban-specific risks and ethical considerations. The developed ethical framework for Urban {AI} applications provides a starting point to pave the way for ethical and sustainable urban {AI} systems that enhance the quality of life for all city residents.},
	pages = {102987},
	journaltitle = {Ain Shams Engineering Journal},
	shortjournal = {Ain Shams Engineering Journal},
	author = {Hendawy, Mennatullah and Ghoz, Lamiaa},
	urldate = {2024-10-15},
	date = {2024-08-25},
	keywords = {Artificial intelligence, {AI} ethics, Smart cities, Urban {AI}},
}

@article{tsao_beyond_2024,
	title = {Beyond the author: Artificial intelligence, creative writing and intellectual emancipation},
	volume = {102},
	issn = {0304-422X},
	url = {https://www.sciencedirect.com/science/article/pii/S0304422X24000044},
	doi = {10.1016/j.poetic.2024.101865},
	shorttitle = {Beyond the author},
	abstract = {This study explores university students’ engagement with Generative Artificial Intelligence ({GenAI}) tools for creative writing and graphic storytelling, drawing on Jacques Rancière's philosophy of intellectual equality and emancipation. Qualitative data analysis from a co-curricular creative writing programme, including reflections, surveys, and focus-group interviews, reveals emerging artificial intelligence literacies and students’ improvisational aptitudes for interpreting, subverting, and transforming notions of authorship. Students decentred authorial attribution through the pragmatic adoption of the technology as a creative catalyst, negotiated creative conventions by adopting non-conventional communication strategies, and reconceptualised creativity as distributed across human and non-human agents. Our approach of student-driven learning for autonomous exploration, sense-making, and criticality with {GenAI} indicates the potential for promoting conditions for students to exercise intellectual equality and emancipation. The findings contribute to the understanding of authorship and creativity; begin to contour emerging {GenAI} literacies and competencies; and suggest that creative collaborations with {GenAI} may be a promising way to foster emancipatory practices in the classroom, while nurturing creative and critical skills.},
	pages = {101865},
	journaltitle = {Poetics},
	shortjournal = {Poetics},
	author = {Tsao, Jack and Nogues, Collier},
	urldate = {2024-10-15},
	date = {2024-02-01},
	keywords = {Artificial Intelligence ({AI}) literacies, Creative writing, Creativity, Generative {AI} ({GenAI}), Intellectual emancipation, Jacques Rancière},
}

@article{rodrigues_legal_2020,
	title = {Legal and human rights issues of {AI}: Gaps, challenges and vulnerabilities},
	volume = {4},
	issn = {2666-6596},
	url = {https://www.sciencedirect.com/science/article/pii/S2666659620300056},
	doi = {10.1016/j.jrt.2020.100005},
	shorttitle = {Legal and human rights issues of {AI}},
	abstract = {This article focusses on legal and human rights issues of artificial intelligence ({AI}) being discussed and debated, how they are being addressed, gaps and challenges, and affected human rights principles. Such issues include: algorithmic transparency, cybersecurity vulnerabilities, unfairness, bias and discrimination, lack of contestability, legal personhood issues, intellectual property issues, adverse effects on workers, privacy and data protection issues, liability for damage and lack of accountability. The article uses the frame of ‘vulnerability’ to consolidate the understanding of critical areas of concern and guide risk and impact mitigation efforts to protect human well-being. While recognising the good work carried out in the {AI} law space, and acknowledging this area needs constant evaluation and agility in approach, this article advances the discussion, which is important given the gravity of the impacts of {AI} technologies, particularly on vulnerable individuals and groups, and their human rights.},
	pages = {100005},
	journaltitle = {Journal of Responsible Technology},
	shortjournal = {Journal of Responsible Technology},
	author = {Rodrigues, Rowena},
	urldate = {2024-10-15},
	date = {2020-12-01},
	keywords = {Artificial intelligence, Human rights, {AI}, Legal issues, Vulnerability},
}

@article{corcuera_barcena_increasing_2025,
	title = {Increasing trust in {AI} through privacy preservation and model explainability: Federated Learning of Fuzzy Regression Trees},
	volume = {113},
	issn = {1566-2535},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253524003762},
	doi = {10.1016/j.inffus.2024.102598},
	shorttitle = {Increasing trust in {AI} through privacy preservation and model explainability},
	abstract = {Federated Learning ({FL}) lets multiple data owners collaborate in training a global model without any violation of data privacy, which is a crucial requirement for enhancing users’ trust in Artificial Intelligence ({AI}) systems. Despite the significant momentum recently gained by the {FL} paradigm, most of the existing approaches in the field neglect another key pillar for the trustworthiness of {AI} systems, namely explainability. In this paper, we propose a novel approach for {FL} of fuzzy regression trees ({FRTs}), which are generally acknowledged as highly interpretable by-design models. The proposed {FL} procedure is designed for the scenario of horizontally partitioned data and is based on the transmission of aggregated statistics from the clients to a central server for the tree induction procedure. It is shown that the proposed approach faithfully approximates the ideal case in which the tree induction algorithm is applied on the union of all local datasets, while still ensuring privacy preservation. Furthermore, the {FL} approach brings benefits, in terms of generalization capability, compared to the local learning setting in which each participant learns its own {FRT} based only on the private, local, dataset. The adoption of linear models in the leaf nodes ensures a competitive level of performance, as assessed by an extensive experimental campaign on benchmark datasets. The analysis of the results covers both the aspects of accuracy and interpretability of {FRT}. Finally, we discuss the application of the proposed federated {FRT} to the task of Quality of Experience forecasting in an automotive case-study.},
	pages = {102598},
	journaltitle = {Information Fusion},
	shortjournal = {Information Fusion},
	author = {Corcuera Bárcena, José Luis and Ducange, Pietro and Marcelloni, Francesco and Renda, Alessandro},
	urldate = {2024-10-16},
	date = {2025-01-01},
	keywords = {Explainable Artificial Intelligence, Federated Learning, Fuzzy Regression Trees, Regression models},
	file = {ScienceDirect Snapshot:C\:\\Users\\57314\\Zotero\\storage\\CULT7G2H\\S1566253524003762.html:text/html},
}

@article{noauthor_evaluating_2024,
	title = {Evaluating privacy, security, and trust perceptions in conversational {AI}: A systematic review},
	volume = {159},
	issn = {0747-5632},
	url = {https://www-sciencedirect-com.hemeroteca.lasalle.edu.co/science/article/pii/S0747563224002127},
	doi = {10.1016/j.chb.2024.108344},
	shorttitle = {Evaluating privacy, security, and trust perceptions in conversational {AI}},
	abstract = {Conversational {AI} ({CAI}) systems which encompass voice- and text-based assistants are on the rise and have been largely integrated into people’s everyd…},
	pages = {108344},
	journaltitle = {Computers in Human Behavior},
	urldate = {2024-10-16},
	date = {2024-10-01},
	langid = {american},
	note = {Publisher: Pergamon},
	file = {Snapshot:C\:\\Users\\57314\\Zotero\\storage\\GMV47M9U\\S0747563224002127.html:text/html},
}

@article{martin_artificial_2024,
	title = {Artificial intelligence and its implications for data privacy},
	volume = {58},
	issn = {2352-250X},
	url = {https://www.sciencedirect.com/science/article/pii/S2352250X24000423},
	doi = {10.1016/j.copsyc.2024.101829},
	abstract = {Contemporary, multidisciplinary research sheds light on data privacy implications of artificial intelligence ({AI}). This review adopts an {AI} ecosystem perspective and proposes a process-outcome continuum to classify {AI} technologies; this perspective helps to understand the nuances of {AI} relative to psychological aspects of privacy decision-making. Specifically, different types of {AI} affect traditionally studied privacy decision-making frameworks including the privacy calculus, psychological ownership, and social influence in varied ways. By understanding how the process- or outcome-orientation of an {AI} technology affects privacy decision-making, we explain how {AI} creates privacy benefits but also poses challenges. Future research is needed across privacy decision-making, but also more generally at the intersection of privacy and {AI}, to help foster an ethical, sustainable society.},
	pages = {101829},
	journaltitle = {Current Opinion in Psychology},
	shortjournal = {Current Opinion in Psychology},
	author = {Martin, Kelly D. and Zimmermann, Johanna},
	urldate = {2024-10-16},
	date = {2024-08-01},
	keywords = {Artificial intelligence, Data privacy, Privacy calculus, Psychological ownership},
	file = {ScienceDirect Snapshot:C\:\\Users\\57314\\Zotero\\storage\\MQJKU93U\\S2352250X24000423.html:text/html},
}

@article{gonzalez-gonzalo_trustworthy_2022,
	title = {Trustworthy {AI}: Closing the gap between development and integration of {AI} systems in ophthalmic practice},
	volume = {90},
	issn = {1350-9462},
	url = {https://www.sciencedirect.com/science/article/pii/S1350946221000951},
	doi = {10.1016/j.preteyeres.2021.101034},
	shorttitle = {Trustworthy {AI}},
	abstract = {An increasing number of artificial intelligence ({AI}) systems are being proposed in ophthalmology, motivated by the variety and amount of clinical and imaging data, as well as their potential benefits at the different stages of patient care. Despite achieving close or even superior performance to that of experts, there is a critical gap between development and integration of {AI} systems in ophthalmic practice. This work focuses on the importance of trustworthy {AI} to close that gap. We identify the main aspects or challenges that need to be considered along the {AI} design pipeline so as to generate systems that meet the requirements to be deemed trustworthy, including those concerning accuracy, resiliency, reliability, safety, and accountability. We elaborate on mechanisms and considerations to address those aspects or challenges, and define the roles and responsibilities of the different stakeholders involved in {AI} for ophthalmic care, i.e., {AI} developers, reading centers, healthcare providers, healthcare institutions, ophthalmological societies and working groups or committees, patients, regulatory bodies, and payers. Generating trustworthy {AI} is not a responsibility of a sole stakeholder. There is an impending necessity for a collaborative approach where the different stakeholders are represented along the {AI} design pipeline, from the definition of the intended use to post-market surveillance after regulatory approval. This work contributes to establish such multi-stakeholder interaction and the main action points to be taken so that the potential benefits of {AI} reach real-world ophthalmic settings.},
	pages = {101034},
	journaltitle = {Progress in Retinal and Eye Research},
	shortjournal = {Progress in Retinal and Eye Research},
	author = {González-Gonzalo, Cristina and Thee, Eric F. and Klaver, Caroline C. W. and Lee, Aaron Y. and Schlingemann, Reinier O. and Tufail, Adnan and Verbraak, Frank and Sánchez, Clara I.},
	urldate = {2024-10-16},
	date = {2022-09-01},
	keywords = {Artificial intelligence, Deep learning, Integration, Machine learning, Ophthalmic care, Trustworthiness},
	file = {Texto completo:C\:\\Users\\57314\\Zotero\\storage\\FD9NZBLP\\González-Gonzalo et al. - 2022 - Trustworthy AI Closing the gap between development and integration of AI systems in ophthalmic prac.pdf:application/pdf},
}

@article{mennella_ethical_2024,
	title = {Ethical and regulatory challenges of {AI} technologies in healthcare: A narrative review},
	volume = {10},
	issn = {2405-8440},
	url = {https://www.sciencedirect.com/science/article/pii/S2405844024023284},
	doi = {10.1016/j.heliyon.2024.e26297},
	shorttitle = {Ethical and regulatory challenges of {AI} technologies in healthcare},
	abstract = {Over the past decade, there has been a notable surge in {AI}-driven research, specifically geared toward enhancing crucial clinical processes and outcomes. The potential of {AI}-powered decision support systems to streamline clinical workflows, assist in diagnostics, and enable personalized treatment is increasingly evident. Nevertheless, the introduction of these cutting-edge solutions poses substantial challenges in clinical and care environments, necessitating a thorough exploration of ethical, legal, and regulatory considerations. A robust governance framework is imperative to foster the acceptance and successful implementation of {AI} in healthcare. This article delves deep into the critical ethical and regulatory concerns entangled with the deployment of {AI} systems in clinical practice. It not only provides a comprehensive overview of the role of {AI} technologies but also offers an insightful perspective on the ethical and regulatory challenges, making a pioneering contribution to the field. This research aims to address the current challenges in digital healthcare by presenting valuable recommendations for all stakeholders eager to advance the development and implementation of innovative {AI} systems.},
	pages = {e26297},
	number = {4},
	journaltitle = {Heliyon},
	shortjournal = {Heliyon},
	author = {Mennella, Ciro and Maniscalco, Umberto and De Pietro, Giuseppe and Esposito, Massimo},
	urldate = {2024-10-16},
	date = {2024-02-29},
	keywords = {Artificial intelligence, Decision-making, Ethics, Healthcare, Regulatory guidelines, Technologies},
	file = {Texto completo:C\:\\Users\\57314\\Zotero\\storage\\EEB5HFLS\\Mennella et al. - 2024 - Ethical and regulatory challenges of AI technologies in healthcare A narrative review.pdf:application/pdf},
}

@article{mezgar_ethics_2022,
	title = {From ethics to standards – A path via responsible {AI} to cyber-physical production systems},
	volume = {53},
	issn = {1367-5788},
	url = {https://www.sciencedirect.com/science/article/pii/S1367578822000177},
	doi = {10.1016/j.arcontrol.2022.04.002},
	abstract = {The central claim of the paper is that the development and control of Cyber-Physical Production Systems ({CPPS}) requires a systematic approach to handle and include explicit ethical considerations. Since the contribution of artificial intelligence ({AI}) technologies, and of agent-based models in particular, was instrumental in the evolution of {CPPSs}, approaches of ethical {AI} should be endorsed in {CPPS} development by design. The paper discusses recent advances for ethical {AI} and suggests a pathway from ethical norms towards standards. As it is argued, taking the responsible {AI} approach is promising when tackling the main ethic-related challenges of Cyber-Physical Production Systems. We expose a number of dilemmas to be resolved so that {AI} systems incorporated in {CPPS} cause no damages either in humans, equipment or in the environment and increase the trust in the users of current and future {AI} technologies.},
	pages = {391--404},
	journaltitle = {Annual Reviews in Control},
	shortjournal = {Annual Reviews in Control},
	author = {Mezgár, István and Váncza, József},
	urldate = {2024-10-16},
	date = {2022-01-01},
	keywords = {Agents, Artificial intelligence, Control, Cyber-physical production system, Ethics, Trust},
	file = {ScienceDirect Snapshot:C\:\\Users\\57314\\Zotero\\storage\\8W6VVIRR\\S1367578822000177.html:text/html;Versión aceptada:C\:\\Users\\57314\\Zotero\\storage\\LRPT9JIX\\Mezgár y Váncza - 2022 - From ethics to standards – A path via responsible AI to cyber-physical production systems.pdf:application/pdf},
}
@article{noauthor_ai_2024,
	title = {{AI} Fairness–From Machine Learning to Federated Learning},
	volume = {139},
	issn = {1526-1492},
	url = {https://www-sciencedirect-com.hemeroteca.lasalle.edu.co/org/science/article/pii/S1526149224002108},
	doi = {10.32604/cmes.2023.029451},
	abstract = {This article reviews the theory of fairness in {AI}–from machine learning to federated learning, where the constraints on precision {AI} fairness and pers…},
	pages = {1203--1215},
	number = {2},
	journaltitle = {{CMES} - Computer Modeling in Engineering and Sciences},
	urldate = {2024-10-16},
	date = {2024-01-29},
	langid = {american},
	file = {Snapshot:C\:\\Users\\57314\\Zotero\\storage\\3ISZ5MCX\\S1526149224002108.html:text/html;Texto completo:C\:\\Users\\57314\\Zotero\\storage\\67U89JR9\\2024 - AI Fairness–From Machine Learning to Federated Learning.pdf:application/pdf},
}

@article{heyder_ethical_2023,
	title = {Ethical management of human-{AI} interaction: Theory development review},
	volume = {32},
	issn = {0963-8687},
	url = {https://www.sciencedirect.com/science/article/pii/S0963868723000185},
	doi = {10.1016/j.jsis.2023.101772},
	shorttitle = {Ethical management of human-{AI} interaction},
	abstract = {{AI}-based technologies have changed the nature of the symbiosis between humans and {AI}, and so strategic management of human-{AI} interaction in organizations requires deeper ethical considerations. Aligning {AI} with human values requires a systematic understanding of the ethical management of human-{AI} interaction. We conduct a theoretical review, from a sociotechnical perspective, and analyze ethical management of human-{AI} interaction through the lens of sociomateriality. Our systematic approach helps explain and clarify the interdependencies between two ethical perspectives – duty and virtue ethics – in sociotechnical systems. We also provide a theoretical framework that leads to seven avenues for future research.},
	pages = {101772},
	number = {3},
	journaltitle = {The Journal of Strategic Information Systems},
	shortjournal = {The Journal of Strategic Information Systems},
	author = {Heyder, Teresa and Passlack, Nina and Posegga, Oliver},
	urldate = {2024-10-16},
	date = {2023-09-01},
	keywords = {Artificial intelligence, Ethics, Human-{AI} interaction, Sociomateriality, Theoretical review},
	file = {ScienceDirect Snapshot:C\:\\Users\\57314\\Zotero\\storage\\SGAK45PJ\\S0963868723000185.html:text/html},
}

@article{gevaert_fairness_2021,
	title = {Fairness and accountability of {AI} in disaster risk management: Opportunities and challenges},
	volume = {2},
	issn = {2666-3899},
	url = {https://www.sciencedirect.com/science/article/pii/S2666389921002257},
	doi = {10.1016/j.patter.2021.100363},
	shorttitle = {Fairness and accountability of {AI} in disaster risk management},
	abstract = {Disaster risk management ({DRM}) seeks to help societies prepare for, mitigate, or recover from the adverse impacts of disasters and climate change. Core to {DRM} are disaster risk models that rely heavily on geospatial data about the natural and built environments. Developers are increasingly turning to artificial intelligence ({AI}) to improve the quality of these models. Yet, there is still little understanding of how the extent of hidden geospatial biases affects disaster risk models and how accountability relationships are affected by these emerging actors and methods. In many cases, there is also a disconnect between the algorithm designers and the communities where the research is conducted or algorithms are implemented. This perspective highlights emerging concerns about the use of {AI} in {DRM}. We discuss potential concerns and illustrate what must be considered from a data science, ethical, and social perspective to ensure the responsible usage of {AI} in this field.},
	pages = {100363},
	number = {11},
	journaltitle = {Patterns},
	shortjournal = {Patterns},
	author = {Gevaert, Caroline M. and Carman, Mary and Rosman, Benjamin and Georgiadou, Yola and Soden, Robert},
	urldate = {2024-10-16},
	date = {2021-11-12},
	keywords = {accountability, {AI}, artificial intelligence, disaster risk management, {DRM}, geospatial, values},
	file = {Texto completo:C\:\\Users\\57314\\Zotero\\storage\\WECK6LIT\\Gevaert et al. - 2021 - Fairness and accountability of AI in disaster risk management Opportunities and challenges.pdf:application/pdf},
}

@article{sharma_benefits_2024,
	title = {Benefits or concerns of {AI}: A multistakeholder responsibility},
	volume = {157},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328724000119},
	doi = {10.1016/j.futures.2024.103328},
	shorttitle = {Benefits or concerns of {AI}},
	abstract = {This article provides a comprehensive overview of the current state of academic research on benefits and concerns of artificial intelligence ({AI}) in everyday life. Findings from the literature presented in this article offer useful guidance for the stakeholders who are looking into establishing governance practices for responsible artificial intelligence ({AI}) so that the future of our smart societies is safe, inclusive, and sustainable. This synthesis of literature review connects the dots from various academic disciplines concluding with a model theoretical framework for responsible {AI} in a multi-stakeholder arrangement. Based on the findings from the literature review, two interesting discussions are presented in this article. The discussions reflect upon inevitable multidisciplinary complexity of the topic {AI} and society. Discussion 1, by breaking down complex concepts and providing clear explanations, offers useful insights on the reasons why ethical considerations have become a focal concern for {AI} governance. Similarly, discussion 2 highlights the need for a multi-stakeholder approach for the responsible adoption of {AI}. Overall, this article contributes to the ongoing discussions and debates about the responsible {AI} by systematically building an argument as to why a multi-stakeholder approach is vital to address the societal concerns of {AI}.},
	pages = {103328},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Sharma, Somesh},
	urldate = {2024-10-16},
	date = {2024-03-01},
	keywords = {{AI}-benefits, {AI}-concerns, Automation, Multistakeholder framework, Responsible {AI}, Smart societies},
	file = {ScienceDirect Snapshot:C\:\\Users\\57314\\Zotero\\storage\\4JG2BSKW\\S0016328724000119.html:text/html},
}

@article{cancela-outeda_eus_2024,
	title = {The {EU}'s {AI} act: A framework for collaborative governance},
	volume = {27},
	issn = {2542-6605},
	url = {https://www.sciencedirect.com/science/article/pii/S2542660524002324},
	doi = {10.1016/j.iot.2024.101291},
	shorttitle = {The {EU}'s {AI} act},
	abstract = {In February 2024, the Council and the European Parliament ({EP}) agreed on the Artificial Intelligence Regulation (usually known as {AI} Act, {AIA}) .22We use the {AI} Act version P9\_TA(2024)0138 Artificial Intelligence Act European Parliament legislative resolution of 13 March 2024 on the proposal for a regulation of the European Parliament and of the Council on laying down harmonised rules on Artificial Intelligence (Artificial Intelligence Act) and amending certain Union Legislative Acts ({COM}(2021)0206–C9-0146/2021–2021/0106({COD})). https://www.europarl.europa.eu/doceo/document/{TA}-9-2024-0138\_EN.pdf This regulation evaluates {AI} applications to ensure they are used ethically and responsibly, promoting the development of safe and lawful {AI} across the {EU}'s single market. It establishes a comprehensive legal framework with a risk-based approach, aiming to achieve a balance between protecting the health, safety, and fundamental rights of European citizens and ensuring that the growing {AI} industry in Europe remains competitive and continues to innovate. The {AIA} also includes governance mechanisms oriented towards achieving effective implementation throughout the {EU}. For this purpose, a European Artificial Intelligence Office has already been established. In accordance with the provisions of the forthcoming {AIA}, it will establish a European Artificial Intelligence Board, an advisory forum, and a scientific panel. Furthermore, it will be set up at the national level the so-called national competent authorities. In this way, a single European governance system for {AI} is emerging, inspired by collaborative governance, which is essential for achieving fair and effective implementation of {AI} regulations across the {EU}. The main objective of this text is to critically examine the governance system established by the {AIA}. Using the contents of the current version of the {AIA} (April 2024), this analysis delves into the mechanisms and structures designed to implement {AI} across the {EU}. As a conclusion, it offers a critical perspective on the collaborative governance, highlighting its strengths and potential areas for improvement.},
	pages = {101291},
	journaltitle = {Internet of Things},
	shortjournal = {Internet of Things},
	author = {Cancela-Outeda, Celso},
	urldate = {2024-10-16},
	date = {2024-10-01},
	keywords = {“black box”, Civil society, Collaborative logic, Governance, Popularization, Stakeholders},
	file = {ScienceDirect Snapshot:C\:\\Users\\57314\\Zotero\\storage\\794PBFTI\\S2542660524002324.html:text/html},
}

@article{kazim_high-level_2021,
	title = {A high-level overview of {AI} ethics},
	volume = {2},
	issn = {2666-3899},
	url = {https://www.sciencedirect.com/science/article/pii/S2666389921001574},
	doi = {10.1016/j.patter.2021.100314},
	abstract = {Artificial intelligence ({AI}) ethics is a field that has emerged as a response to the growing concern regarding the impact of {AI}. It can be read as a nascent field and as a subset of the wider field of digital ethics, which addresses concerns raised by the development and deployment of new digital technologies, such as {AI}, big data analytics, and blockchain technologies. The principle aim of this article is to provide a high-level conceptual discussion of the field by way of introducing basic concepts and sketching approaches and central themes in {AI} ethics. The first part introduces concepts by noting what is being referred to by “{AI}” and “ethics”, etc.; the second part explores some predecessors to {AI} ethics, namely engineering ethics, philosophy of technology, and science and technology studies; the third part discusses three current approaches to {AI} ethics namely, principles, processes, and ethical consciousness; and finally, the fourth part discusses central themes in translating ethics in to engineering practice. We conclude by summarizing and noting the inherent interdisciplinary future directions and debates in {AI} ethics.},
	pages = {100314},
	number = {9},
	journaltitle = {Patterns},
	shortjournal = {Patterns},
	author = {Kazim, Emre and Koshiyama, Adriano Soares},
	urldate = {2024-10-16},
	date = {2021-09-10},
	keywords = {{AI} ethics, artificial intelligence, governance, humane-{AI}, law, machine learning, philosophy, regulation, Trustworthy {AI}},
	file = {ScienceDirect Snapshot:C\:\\Users\\57314\\Zotero\\storage\\F7SP7ZFB\\S2666389921001574.html:text/html;Texto completo:C\:\\Users\\57314\\Zotero\\storage\\39NSJVJK\\Kazim y Koshiyama - 2021 - A high-level overview of AI ethics.pdf:application/pdf},
}
